---
title: 'Presidential Speech'
output:
  pdf_document: default

```{r, echo=FALSE}
require(knitr)

getwd()

```
>#**U.S. Presidents:**
>#**What did they say about education? How did they say? Is Trump an Alien to education?**
<center>Author: Elune </center>  \n

![US.Presidents](./figs/Presidents.jpg) \n  
---
<font size=3>
The inauguration speech is one of the most important speeches for U.S. Presidents. In this project, I applied texting mining techniques to explore what they said during their inauguration speech, what strategies they adopted, and what kind of emotion they intended to convey in Intriguingly, we identified a significant trend on their speaking strategy and interesting clusters of their topics, particularly in edcuation.   


```{r,warning=FALSE,error=FALSE,echo=FALSE}
setwd("~/GitHub/TM-speech")
##Fisrstly, we check all needed packages and configurate the enviroment.
########install packages and  enviromnet cofiguration
packages.used=c("rvest", "tibble", "qdap", "ggplot2",
                "sentimentr", "gplots", "dplyr","gcookbook",
                "tm", "syuzhet", "factoextra", "scales", "RColorBrewer","wordcloud",
                "RANN", "tm", "topicmodels","beeswarm","cluster","tidytext")

# check packages that need to be installed.
packages.needed=setdiff(packages.used, 
                        intersect(installed.packages()[,1], 
                                  packages.used))
# install additional packages
if(length(packages.needed)>0){
  install.packages(packages.needed, dependencies = TRUE)
}

#Configerate JAVA_Home
Sys.setenv(JAVA_HOME='')

# load packages
library("rvest")
library("tibble")
library("qdap")
library("sentimentr")
library("gplots")
library("dplyr")
library("tm")
library("syuzhet")
library("factoextra")
library("scales")
library("RColorBrewer")
library("RANN")
library("tm")
library("topicmodels")
library("beeswarm")
library("cluster") 
library("tidytext")
library("wordcloud")
library("RColorBrewer")
library("ggplot2")
library("gcookbook")

```

---

##Sentence Analysis: \n

Starting from the easiest method, I analyze the number and length of sentences for each president to identify interesting trend.
```{r,warning=FALSE,include=FALSE,echo=FALSE}
###setwd again
setwd("~/GitHub/TM-speech")
######Preparetion,Data Loading and Preliminary Analysis######
folder.path="data/InauguralSpeeches/"
#Load Information and get order of president according to time
require(xlsx)
inau_info<-read.xlsx("data/InauguralSpeeches/InaugurationInfo.xlsx",sheetName = "Sheet1")
order<-paste(inau_info$File,"-",inau_info$Term,sep= "")   

#Get all txt files and load them 
speeches=list.files(path = folder.path, pattern = "*.txt")
n<-length(speeches)
prez.out=substr(speeches, 6, nchar(speeches)-4)

text.list<-NULL
for (i in speeches){
  New_file<-paste(scan(paste(folder.path,i,sep = ""),what = "character"),collapse=" ")
  text.list<-rbind(text.list,New_file) 
}
rownames(text.list)<-prez.out

#reorder the matrix according to time sequence:
text.list<-data.frame(text.list[sapply(order,grep,prez.out),1])
rownames(text.list)<-order

```


```{r,warning=FALSE,echo=FALSE}
#####Convert Paragraph to Sentences######

#Write function to get get word.cound for each senences:
sentence.get<-function(text) {
  sentences=sent_detect(text,
                        endmarks = c("?", ".", "!", "|",";"))
  
  if(length(sentences)>0){
    word.count=word_count(sentences)
  }
  return(word.count)
}

##get sentences for each speeach
sen_length<-apply(text.list,1,sentence.get)

##Use Precidency index to indicate the precident (for the clearer)
names(sen_length)<-c(1:58)
```
For the following analysis, represent each president through index based on their term. the following table to get the president name for necessary interpretation.
```{r}
tables<-as.matrix(order)
colnames(tables)<-c("President Name")
rownames(tables)<-c(1:58)
tables
```
\n

```{r,warning=FALSE}
beeswarm(sen_length,col=rainbow(58),pch=19, 
         method="hex", cex=0.5, horizontal=TRUE, 
         xlab="Sentence Length", ylab="Precidency Index", 
         main="Distribution of Sentence Length")
```
<font color=white>111</font> \n

The beeswarm plot indicates that from George Washington, presidents tend to use shorter sentences in their inauguration speech. \n


>**Shorter sentences are easier to follow**</center> \n

>**Shorter sentences make more sense**</center>   \n

>**Shorter sentences indicate approachability**</center>   \n

\n
That is, they focus more on the communication with the public. They try to make sure that the public understand what they indent to convey and build a down-to-earth image. Then we select several famous presidents in different historical period: George Washington(1), John Tyler(14) Abraham Lincoln(19) Franklin D. Roosevelt (38), John F. Kennedy (44) and Barack Obama (56) to make comparision.  The trend is evident. 
```{r,warning=FALSE}

#
ex1<-sen_length[c(1,14,19,38,44,56)]
beeswarm(ex1,col=rainbow(8),pch=19, 
         method="hex", cex=0.8, horizontal=TRUE, 
         xlab="Sentence Length", ylab="Precidency Index", 
         main="Distribution of Sentence Length")
```
<font color=white>111</font> \n

```




```

The we explore the contemporary era and focus on Donald Trump(58).
```{r,warning=FALSE}

ex2<-sen_length[50:58]
beeswarm(ex2,col=rainbow(8),pch=19, 
         method="hex", cex=0.8, horizontal=TRUE, 
         xlab="Sentence Length", ylab="Precidency Index", 
         main="Distribution of Sentence Length")
```  
<font color=white>111</font> \n

From the above picture, we can’t detect significant difference between Trump and other presidents.  \n

####**Part 1 Conclusion:**  
\n
Presidents tend to use more shorter sentences to keep effective communication between them and the public. In terms of this, Trump is not heterogeneous and adopt the same speaking strategy.

<center>![Trump1](./figs/Trump1.jpg)</center>
---


##Part 2: Topic Modelling  \n

###2.1: Topic Allocation  \n

Besides how they give a speech, we may be also curious about what they say. Moreover, we are interested in how indicative their topics is to reveal the current situation of America. In part 2, I adopt topic modeling method to explore their speech topics and the weights on each topic for each president.
```{r,warning=FALSE,echo=FALSE}
########Pre-processing the data#####


###we build the corup using our text.list 
docs<-Corpus(VectorSource(unlist(text.list)))
#remove potentially problematic symbols
docs <-tm_map(docs,content_transformer(tolower))
#remove punctuation
docs <- tm_map(docs, removePunctuation)
#Strip digits
docs <- tm_map(docs, removeNumbers)
#remove stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
#remove whitespace
docs <- tm_map(docs, stripWhitespace)
#Stem document
docs <- tm_map(docs,stemDocument)
dtm <- DocumentTermMatrix(docs)

##wordcloud
ff.dtm<-tidy(dtm)

wordcloud(ff.dtm$term[ff.dtm$document==58],ff.dtm$count[ff.dtm2$document==58], scale=c(2.5,.2),min.freq=0,
          max.words=60, random.order=FALSE, rot.per=.15, colors=brewer.pal(8,"Dark2"))

```

#####Topic Modelling by the LDA latent dirichlet allocation method#####

burnin <- 4000
iter <- 2000
thin <- 500
seed <-list(2003,5,63,100001,765)
nstart <- 5
best <- TRUE
#Number of topics
k <- 10
```





```{r,warning=FALSE,echo=FALSE}
#Run LDA using Gibbs sampling
ldaOut <-LDA(dtm, k, method="Gibbs", control=list(nstart=nstart, 
                                                  seed = seed, best=best,
                                                  burnin = burnin, iter = iter, 
                                                  thin=thin))
ldaOut.topics <- as.matrix(topics(ldaOut))
ldaOut.terms <- as.matrix(terms(ldaOut,20))
topicProbabilities <- as.data.frame(ldaOut@gamma)
write.csv(topicProbabilities,file=paste("./TopicProbabilities1.csv"))
terms.beta=ldaOut@beta
terms.beta=scale(terms.beta)
topics.terms=NULL
for(i in 1:k){
  topics.terms=rbind(topics.terms, ldaOut@terms[order(terms.beta[i,], decreasing = TRUE)[1:7]])
}
#topics.terms
#ldaOut.terms

```
\n
I set topic numbers to be 10 and I manually tag them as "Education", "Children", "Disabilities", "Schools", "Income", "WorkingFamilies","Immigrant","achievement", "dream" and "America" after analyzing the keywords for each topic. \n

<center>![10 Topics](./figs/topics.png)</center>
\n




```{r}
topics.hash<-c("Patriotism","Liberty","America","Economy","WorkingFamilies", "Greetings","History", "ForeignPolicy", "Government","Unity")
ldatopic<-as.vector(ldaOut.topics)
ldahash<-topics.hash[ldaOut.topics]
colnames(topicProbabilities)<-topics.hash
```
\n
Then, I use heatmap plot to see the weight allocation of topics for each president. And an indicative trend appears. 
```{r,warning=FALSE,echo=FALSE}
heatmap.2(as.matrix(topicProbabilities), Rowv = FALSE,
          scale = "column", key=T, 
          col = bluered(60),
          cexRow = 0.9, cexCol = 0.9, margins = c(8, 8),
          trace = "none", density.info = "none")
abline(h=0.56,col="Blue",lwd=2)
abline(h=0.415,col="Cyan",lwd=2)
abline(h=0.32,col="Green",lwd=2)
abline(h=0.08,col="Yellow",lwd=2)
legend("topright",legend=c("Before 1860","1860 To 1945","1945 To 1968","1968 To Present"),lty = 1,col=c("Blue","Cyan","Green","Yellow"))
```
<font color=white>111</font> \n

Note that red color indicates more weights on that topic. From the heatmap, we identify interesting trend: presidents that in same era tends to have similar weight allocation among the topics. And when relating them with the America history, the results are not spurring and even indicative. 


####**Interpretation:**

>**In all, what they say in speech can indicate what challenge America is faced.**</center> \n 
\n


###2.2: Clustering of presidents according to topics
\n
Suddenly coming to the above interpretation may be not convincing. In the part, I perform presidents clustering based on the topics to see whether our belief is correct. 
```{r}
####Clustering
mydata<-as.matrix(topicProbabilities)
fit <- kmeans(mydata,4,nstart=20)
#fit$cluster[58]
clusplot(mydata, fit$cluster, color=TRUE, shade=TRUE, labels=2,lines = 0,main="Cluster plot of Presidents According to Topics")
```
<font color=white>111</font> \n

From the plot, we can see, the K-mean clustering provide support for our interpretation:   

>**Contemporaneous presidents are clustered in same group**</center> \n

This means that during different historical periods, America is faced with different challenges and presidents Inauguration speech will talk more about those challenges. We can gain information about current situations about America from president’s speech. 

Now,let's have a further analysis.
```{r}
fit$cluster
fit$cluster[58]
```
\n
We see that cluster 3 mainly contains the contemporary presidents, and Trump is assigned to that Group. We may conclude that Trump doesn’t deviate a lot from the main topics of current America. Within the basic structure, Trump may have his own trait. Now, let’s have a look at what Trump said:
```{r,warnings=FALSE,}
docs2<-Corpus(VectorSource(unlist(text.list)))
docs2<-tm_map(docs2, stripWhitespace)
docs2<-tm_map(docs2, content_transformer(tolower))
docs2<-tm_map(docs2, removeWords, stopwords("english"))
docs2<-tm_map(docs2, removeWords, character(0))
docs2<-tm_map(docs2, removePunctuation)
dtm2<- DocumentTermMatrix(docs2,control = list(weighting =function(x) weightTfIdf(x, normalize =FALSE),stopwords = TRUE))
ff.dtm2<-tidy(dtm2)
wordcloud(ff.dtm2$term[ff.dtm2$document==58],ff.dtm2$count[ff.dtm2$document==58], scale=c(2.5,.2),min.freq=2,
          max.words=100, random.order=FALSE, rot.per=.15, colors=brewer.pal(8,"Dark2"))
```
<font color=white>111</font> \n

The most significant words are “America”, “Borders”, ”Protection”, “Dreams” and “Everyone”. \n

####**Part 2 Conclusion:**  
From the topic modelling, we conclude that inauguration speech can reveal the problems that American was faced and can indicate the emphasis of the president’s policy. 

For Trump, as one of the controversial president, he doesn’t make himself so different in term of the topics. While the key words show that he may focus more on focus more on:\n

>**protectionism, nationalism and “tried” to “protect” “America” and each American individual. ** \n 

<center>![Trump2](./figs/Trump2.jpg)</center> \n \n

---

##Part 3: Sentiment Analysis \n

Apart from the topics and sentence lengths, we also want to know what kind of emotions they wanted to convey during their speech. Therefore, we conducted the sentiment analysis to identify the emotion contained in each sentence of their speeches. \n

I incorporate “trust”，“disgust”，“surprise”，“sadness”，“fear”, “joy”, and “anticipation”as emotional categories. Based on the result for each sentence, we summarize them and plot the heat map to see the weights for different emotion. \n
```{r,warnings=FALSE,echo=FALSE,error=FALSE}
##bulit functions to obtainin the emotion
emotion.get<-function(text) {
  sentence.list<-NULL
  sentences=sent_detect(text,
                        endmarks = c("?", ".", "!", "|",";"))
  if(length(sentences)>0){
    word.count=word_count(sentences)
    emotions=get_nrc_sentiment(sentences)
    emotions=diag(1/(word.count+0.01))%*%as.matrix(emotions)
  }
  return(emotions)
}

emotion.list<-apply(text.list,1,emotion.get)
names(emotion.list)<-c(1:58)

emotion.total<-sapply(emotion.list,colSums,na.rm=T)
emotion.total<-t(emotion.total)

heatmap.2(emotion.total[,c(1:8)],
          scale = "row", key=T, 
          col = bluered(60),
          cexRow = 0.9, cexCol = 0.9, margins = c(8, 8),
          trace = "none", density.info = "none")
```
<font color=white>111</font> \n

The above graph indicates that, different from the weight allocation of topics, nearly all the presidents convey more positive emotion like Trust, Joy and Anticipation. \n

